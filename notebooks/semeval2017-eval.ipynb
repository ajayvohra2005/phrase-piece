{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6983fbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "lambda_client = boto3.client(\"lambda\")\n",
    "s3_client = boto3.client(\"s3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e204c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "create_corpus_arn = \"\"\n",
    "\n",
    "def create_corpus(name, s3_uri):\n",
    "\n",
    "  json_data = { \n",
    "    \"CorpusName\": name,\n",
    "    \"S3Uri\": s3_uri,\n",
    "    \"SimThreshold\": \"0.10\"\n",
    "  }\n",
    "  \n",
    "  payload = json.dumps({ \"body\": json.dumps(json_data) })\n",
    "\n",
    "  response = lambda_client.invoke(\n",
    "      FunctionName=create_corpus_arn,\n",
    "      InvocationType='RequestResponse',\n",
    "      Payload=payload\n",
    "  )\n",
    "\n",
    "  print(response)\n",
    "  \n",
    "  json_obj = json.loads(response['Payload'].read())\n",
    "  data = json.loads(json_obj['body'])\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c15a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "sfn_client=boto3.client('stepfunctions')\n",
    "def wait_for_sfn_sm(sm_execution_arn):\n",
    "    status = 'RUNNING'\n",
    "    while status == 'RUNNING':\n",
    "        response = sfn_client.describe_execution(executionArn=sm_execution_arn)\n",
    "        status = response.get('status')\n",
    "        if status == 'RUNNING':\n",
    "            time.sleep(15)\n",
    "        \n",
    "    return status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7783ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def s3_bucket_keys(s3_client, bucket_name, bucket_prefix):\n",
    "    \"\"\"Generator for listing S3 bucket keys matching prefix\"\"\"\n",
    "\n",
    "    kwargs = {'Bucket': bucket_name, 'Prefix': bucket_prefix}\n",
    "    while True:\n",
    "        resp = s3_client.list_objects_v2(**kwargs)\n",
    "        for obj in resp['Contents']:\n",
    "            yield obj['Key']\n",
    "\n",
    "        try:\n",
    "            kwargs['ContinuationToken'] = resp['NextContinuationToken']\n",
    "        except KeyError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfec8606",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_corpus(corpus_id):\n",
    "  payload = json.dumps( { \"body\": \"{ \\\"CorpusId\\\": \\\"\" + corpus_id + \"\\\" }\" } )\n",
    "\n",
    "  print(payload)\n",
    "  response = lambda_client.invoke(\n",
    "      FunctionName='',\n",
    "      InvocationType='RequestResponse',\n",
    "      Payload=payload\n",
    "  )\n",
    "\n",
    "  print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b166040",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_uris = []\n",
    "\n",
    "universe_bucket = \n",
    "bucket_prefix = \"midas/semeval2017/documents/\"\n",
    "\n",
    "for key in s3_bucket_keys(s3_client=s3_client, bucket_name=universe_bucket, bucket_prefix=bucket_prefix):\n",
    "    s3_uris.append(f\"s3://{universe_bucket}/{key}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f713b234",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "sms = []\n",
    "count = 0\n",
    "max_count = 1000\n",
    "\n",
    "filter_names = []\n",
    "for s3_uri in s3_uris:\n",
    "    m=re.match(r\".+\\/id=(\\w+)\\/.+\", s3_uri)\n",
    "    if m:\n",
    "        name = f\"semeval2017-{m[1]}\"\n",
    "        if filter_names and name not in filter_names:\n",
    "            continue\n",
    "        response = create_corpus(name=name, s3_uri=s3_uri)\n",
    "        sms.append( (name, response['CorpusStateMachine'],  response['CorpusId'], s3_uri) )\n",
    "        count += 1\n",
    "        time.sleep(2)\n",
    "    if count >= max_count:\n",
    "        break\n",
    "print(f\"Create Corpus State Machines running count: {len(sms)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267ad6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_corpus_failed = []\n",
    "for name, sm, corpus_id, s3_uri in sms:\n",
    "    status = wait_for_sfn_sm(sm_execution_arn=sm)\n",
    "    if status != \"SUCCEEDED\":\n",
    "        delete_corpus(corpus_id=corpus_id)\n",
    "        create_corpus_failed.append((name, s3_uri))\n",
    "\n",
    "if create_corpus_failed:\n",
    "    print(f\"Create Corpus Failed: {create_corpus_failed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26281242",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "while len(create_corpus_failed) > 0:\n",
    "    sms.clear()\n",
    "    for name, s3_uri in create_corpus_failed:\n",
    "        response = create_corpus(name=name, s3_uri=s3_uri)\n",
    "        sms.append( (name, response['CorpusStateMachine'],  response['CorpusId'], s3_uri) )\n",
    "        time.sleep(60)\n",
    "\n",
    "    create_corpus_failed.clear()\n",
    "    for name, sm, corpus_id, s3_uri in sms:\n",
    "        status = wait_for_sfn_sm(sm_execution_arn=sm)\n",
    "        if status != \"SUCCEEDED\":\n",
    "            delete_corpus(corpus_id=corpus_id)\n",
    "            create_corpus_failed.append((name, s3_uri))\n",
    "\n",
    "    if create_corpus_failed:\n",
    "        print(f\"Create corpus Failed: {create_corpus_failed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91b6b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempfile import NamedTemporaryFile\n",
    "import gzip\n",
    "import json\n",
    "\n",
    "corpora_bucket = \"\"\n",
    "\n",
    "def get_candidates(name):\n",
    "    bucket_prefix = f\"keyphrases/tag={name}/\"\n",
    "        \n",
    "    extracted = []\n",
    "    try:\n",
    "        for key in s3_bucket_keys(s3_client=s3_client, bucket_name=corpora_bucket, bucket_prefix=bucket_prefix):\n",
    "            with NamedTemporaryFile(mode='w+b', delete=True) as file_obj:\n",
    "                s3_client.download_fileobj(corpora_bucket, key, file_obj)\n",
    "                file_obj.seek(0)\n",
    "\n",
    "                with gzip.open(file_obj, mode=\"rb\") as gzip_obj:\n",
    "                    while (line := gzip_obj.readline()):\n",
    "                        json_obj=json.loads(line.decode('utf-8'))\n",
    "                        keyphrase = json_obj['keyphrase']\n",
    "                        #keyphrase = re.sub(pattern, '', keyphrase)\n",
    "                        phrase_piece = json_obj['phrase_piece']\n",
    "                        extracted.append( (keyphrase, phrase_piece) )\n",
    "    except KeyError as e:\n",
    "        print(e)\n",
    "\n",
    "    extracted.sort(key = lambda x: x[1], reverse=True)\n",
    "    return extracted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77be5e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "universe_bucket = \n",
    "\n",
    "def get_references(name):\n",
    "    bucket_prefix = f\"midas/semeval2017/keyphrases/id={name}/\"\n",
    "        \n",
    "    gt = []\n",
    "    try:\n",
    "        for key in s3_bucket_keys(s3_client=s3_client, bucket_name=universe_bucket, bucket_prefix=bucket_prefix):\n",
    "            s3_obj = s3_client.get_object(Bucket=universe_bucket, Key=key)\n",
    "            json_str = s3_obj['Body'].read().decode('utf-8')\n",
    "            json_obj = json.loads(json_str)\n",
    "            gt.extend(json_obj['keyphrases'])\n",
    "    except KeyError as e:\n",
    "        print(e)\n",
    "\n",
    "    return gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabcbba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamodb = boto3.resource('dynamodb')\n",
    "table = dynamodb.Table('')\n",
    "\n",
    "response = table.scan()\n",
    "corpus_data = response['Items']\n",
    "\n",
    "while 'LastEvaluatedKey' in response:\n",
    "    response = table.scan(ExclusiveStartKey=response['LastEvaluatedKey'])\n",
    "    corpus_data.extend(response['Items'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc31df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "semeval2017_corpora=[]\n",
    "prefix = \"semeval2017-\"\n",
    "for item in corpus_data:\n",
    "  corpus_name = item['corpus_name']\n",
    "  if corpus_name.startswith(prefix):\n",
    "    semeval2017_corpora.append(corpus_name)\n",
    "\n",
    "semeval2017_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c435ec5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rouge-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77d6a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "def f_score():\n",
    "\n",
    "    scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "    all_list = []\n",
    "\n",
    "    for name in semeval2017_corpora:\n",
    "        \n",
    "        d_list = []\n",
    "        references = get_references(name.rsplit('-', 1)[1])\n",
    "        candidates = get_candidates(name)\n",
    "        candidates.sort(key = lambda x: x[1], reverse=True)\n",
    "        candidates = candidates[0: len(references)]\n",
    "\n",
    "        for candidate, _ in candidates:\n",
    "            c_list = []\n",
    "            for reference in references:\n",
    "                scores = scorer.score(reference, candidate)\n",
    "                c_list.append(scores['rougeL'])\n",
    "        \n",
    "            c_list.sort(key=lambda x: x.fmeasure, reverse=True)\n",
    "            d_list.append(c_list[0])\n",
    "\n",
    "        precision = 0.0\n",
    "        recall = 0.0\n",
    "        fmeasure = 0.0\n",
    "        total = 0\n",
    "\n",
    "        for s in d_list:\n",
    "            total += 1\n",
    "            precision += s.precision\n",
    "            recall += s.recall\n",
    "            fmeasure += s.fmeasure\n",
    "        \n",
    "        all_list.append( ( precision/total, recall/total, fmeasure/total))\n",
    "        \n",
    "\n",
    "    precision = 0.0\n",
    "    recall = 0.0\n",
    "    fmeasure = 0.0\n",
    "    total = 0\n",
    "\n",
    "    for s in all_list:\n",
    "        total += 1\n",
    "        precision += s[0]\n",
    "        recall += s[1]\n",
    "        fmeasure += s[2]\n",
    "\n",
    "    return precision/total, recall/total, fmeasure/total\n",
    "\n",
    "\n",
    "p,r,f = f_score()\n",
    "print(p,r,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "4dbc9917bcaa9a9fa434c727723b90f93ecc3435121eacd019fcd02c268a833c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
